{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ed5b9-4b32-4444-93af-98b7033038c8",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e388ee13-5e7a-4b93-a896-622f8a4214cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from subprocess import call\n",
    "import fractions\n",
    "def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
    "\n",
    "#from options.train_options import TrainOptions\n",
    "#from data.data_loader import CreateDataLoader\n",
    "#from models.models import create_model\n",
    "#import util.util as util\n",
    "#from util.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6583c-3638-4844-be41-b354d6582c2a",
   "metadata": {},
   "source": [
    "#### Input Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79de543-c3e4-42f6-a31b-cb6ffaf33d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'name' : 'label2city',\n",
    "    'gpu_ids' : [0],\n",
    "    'checkpoints_dir' : '/vol2/reflective_shadow/checkpoints_v8/',\n",
    "    'model' : 'pix2pixHD',\n",
    "    'norm' : 'instance',\n",
    "    'use_dropout' : True,\n",
    "    'data_type' : 32,\n",
    "    'verbose' : False,\n",
    "    'fp16' : False,\n",
    "    'local_rank' : 0,\n",
    "    \n",
    "    # Input/Output sizes\n",
    "    'batchSize' : 1,\n",
    "    'loadSize' : 1024,\n",
    "    'fineSize' : 512,\n",
    "    'label_nc' : 35,\n",
    "    'input_nc' : 3,\n",
    "    'output_nc' : 3,\n",
    "    \n",
    "    # for setting inputs\n",
    "    'dataroot' : './datasets/cityscapes/',\n",
    "    'resize_or_crop' : 'scale_width', #'scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]\n",
    "    'serial_batches' : False,\n",
    "    'no_flip' : False,\n",
    "    'nThreads' : 2,\n",
    "    'max_dataset_size' : float(\"inf\"),\n",
    "    \n",
    "    \n",
    "    # for displays\n",
    "    'display_winsize'=512,  #help='display window size'\n",
    "    'tf_log'=False, #help='if specified, use tensorboard logging. Requires tensorflow installed'\n",
    "\n",
    "    # for generator\n",
    "    'netG' : 'global', #help='selects model to use for netG'\n",
    "    'ngf' : 64, #help='# of gen filters in first conv layer'\n",
    "    'n_downsample_global' : 4, #help='number of downsampling layers in netG'\n",
    "    'n_blocks_global' : 9, #help='number of residual blocks in the global generator network'\n",
    "    'n_blocks_local' : 3, #help='number of residual blocks in the local enhancer network'\n",
    "    'n_local_enhancers' : 1, #help='number of local enhancers to use'\n",
    "    'niter_fix_global' : 0, #help='number of epochs that we only train the outmost local enhancer'\n",
    "\n",
    "    # for instance-wise features\n",
    "    'no_instance' : True, #help='if specified, do *not* add instance map as input'\n",
    "    'instance_feat' : False, #help='if specified, add encoded instance features as input'\n",
    "    'label_feat' : False, #help='if specified, add encoded label features as input'\n",
    "    'feat_num' : 3, #help='vector length for encoded features'\n",
    "    'load_features':False, #help='if specified, load precomputed feature maps'\n",
    "    'n_downsample_E' : 4, #help='# of downsampling layers in encoder'\n",
    "    'nef' : 16, #help='# of encoder filters in the first conv layer'\n",
    "    'n_clusters' : 10, #help='number of clusters for features'\n",
    "    \n",
    "    # for displays\n",
    "    'display_freq' : 100, #help='frequency of showing training results on screen'\n",
    "    'print_freq' : 100, #help='frequency of showing training results on console'\n",
    "    'save_latest_freq' : 1000, #help='frequency of saving the latest results'\n",
    "    'save_epoch_freq' : 10, #help='frequency of saving checkpoints at the end of epochs' \n",
    "    'no_html' : False, #help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'\n",
    "    'debug' : False, #help='only do one epoch and displays at each iteration'\n",
    "\n",
    "    # for training\n",
    "    'continue_train'False, #help='continue training: load the latest model'\n",
    "    'load_pretrain' : '', #help='load the pretrained model from the specified location'\n",
    "    'which_epoch' : 'latest', #help='which epoch to load? set to latest to use latest cached model'\n",
    "    'phase' : 'train', #help='train, val, test, etc'\n",
    "    'niter' : 100, #help='# of iter at starting learning rate'\n",
    "    'niter_decay' : 100, #help='# of iter to linearly decay learning rate to zero'\n",
    "    'beta1' : 0.5, #help='momentum term of adam'\n",
    "    'lr' : 0.0002, #help='initial learning rate for adam'\n",
    "\n",
    "    # for discriminators        \n",
    "    'num_D' : 2, #help='number of discriminators to use'\n",
    "    'n_layers_D' : 3, #help='only used if which_model_netD==n_layers'\n",
    "    'ndf' : 64, #help='# of discrim filters in first conv layer'\n",
    "    'lambda_feat' : 10.0, #help='weight for feature matching loss'\n",
    "    'no_ganFeat_loss' : False, #help='if specified, do *not* use discriminator feature matching loss'\n",
    "    'no_vgg_loss' : False, #help='if specified, do *not* use VGG feature matching loss'\n",
    "    'no_lsgan' : False, #help='do *not* use least square GAN, if false, use vanilla GAN'\n",
    "    'pool_size' : 0, #help='the size of image buffer that stores previously generated images'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae483f9b-9024-4e4b-b58e-a81d88e98b3e",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7708a4-352b-4cb3-bfcb-b7b69f125b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dcef3-ed27-40f2-a997-e34672604fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f8b79-879f-454e-808b-33aadc1e00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0\n",
    "\n",
    "opt.print_freq = lcm(opt.print_freq, opt.batchSize)    \n",
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10\n",
    "\n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)\n",
    "visualizer = Visualizer(opt)\n",
    "if opt.fp16:    \n",
    "    from apex import amp\n",
    "    model, [optimizer_G, optimizer_D] = amp.initialize(model, [model.optimizer_G, model.optimizer_D], opt_level='O1')             \n",
    "    model = torch.nn.DataParallel(model, device_ids=opt.gpu_ids)\n",
    "else:\n",
    "    optimizer_G, optimizer_D = model.module.optimizer_G, model.module.optimizer_D\n",
    "\n",
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == display_delta\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        optimizer_G.zero_grad()\n",
    "        if opt.fp16:                                \n",
    "            with amp.scale_loss(loss_G, optimizer_G) as scaled_loss: scaled_loss.backward()                \n",
    "        else:\n",
    "            loss_G.backward()          \n",
    "        optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        optimizer_D.zero_grad()\n",
    "        if opt.fp16:                                \n",
    "            with amp.scale_loss(loss_D, optimizer_D) as scaled_loss: scaled_loss.backward()                \n",
    "        else:\n",
    "            loss_D.backward()        \n",
    "        optimizer_D.step()        \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            errors = {k: v.data.item() if not isinstance(v, int) else v for k, v in loss_dict.items()}            \n",
    "            t = (time.time() - iter_start_time) / opt.print_freq\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "            #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine_audio",
   "language": "python",
   "name": "engine_audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
