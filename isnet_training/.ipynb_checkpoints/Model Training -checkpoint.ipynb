{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakesh/anaconda3/envs/DIS_bg_remove/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import torch, gc\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data_loader_cache import get_im_gt_name_dict, create_dataloaders, GOSRandomHFlip, GOSResize, GOSRandomCrop, GOSNormalize #GOSDatasetCache,\n",
    "from basics import  f1_mae_torch #normPRED, GOSPRF1ScoresCache,f1score_torch,\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ce354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_encoder(train_dataloaders,\n",
    "                   train_datasets, \n",
    "                   valid_dataloaders, \n",
    "                   valid_datasets, \n",
    "                   hypar, \n",
    "                   train_dataloaders_val, \n",
    "                   train_datasets_val): #model_path, model_save_fre, max_ite=1000000):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(hypar[\"seed\"])\n",
    "    else:\n",
    "        torch.manual_seed(hypar[\"seed\"])\n",
    "\n",
    "    print(\"define gt encoder ...\")\n",
    "    net = ISNetGTEncoder() #UNETGTENCODERCombine()\n",
    "    ## load the existing model gt encoder\n",
    "    if(hypar[\"gt_encoder_model\"]!=\"\"):\n",
    "        model_path = hypar[\"model_path\"]+\"/\"+hypar[\"gt_encoder_model\"]\n",
    "        if torch.cuda.is_available():\n",
    "            net.load_state_dict(torch.load(model_path))\n",
    "            net.cuda()\n",
    "        else:\n",
    "            net.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n",
    "        print(\"gt encoder restored from the saved weights ...\")\n",
    "        return net ############\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    print(\"--- define optimizer for GT Encoder---\")\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    model_path = hypar[\"model_path\"]\n",
    "    model_save_fre = hypar[\"model_save_fre\"]\n",
    "    max_ite = hypar[\"max_ite\"]\n",
    "    batch_size_train = hypar[\"batch_size_train\"]\n",
    "    batch_size_valid = hypar[\"batch_size_valid\"]\n",
    "\n",
    "    if(not os.path.exists(model_path)):\n",
    "        os.mkdir(model_path)\n",
    "\n",
    "    ite_num = hypar[\"start_ite\"] # count the total iteration number\n",
    "    ite_num4val = 0 #\n",
    "    running_loss = 0.0 # count the toal loss\n",
    "    running_tar_loss = 0.0 # count the target output loss\n",
    "    last_f1 = [0 for x in range(len(valid_dataloaders))]\n",
    "\n",
    "    train_num = train_datasets[0].__len__()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    start_last = time.time()\n",
    "    gos_dataloader = train_dataloaders[0]\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "    notgood_cnt = 0\n",
    "    for epoch in range(epoch_num): ## set the epoch num as 100000\n",
    "\n",
    "        for i, data in enumerate(gos_dataloader):\n",
    "\n",
    "            if(ite_num >= max_ite):\n",
    "                print(\"Training Reached the Maximal Iteration Number \", max_ite)\n",
    "                exit()\n",
    "\n",
    "            # start_read = time.time()\n",
    "            ite_num = ite_num + 1\n",
    "            ite_num4val = ite_num4val + 1\n",
    "\n",
    "            # get the inputs\n",
    "            labels = data['label']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "            else:\n",
    "                labels = labels.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                labels_v = Variable(labels.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                labels_v = Variable(labels, requires_grad=False)\n",
    "\n",
    "            # print(\"time lapse for data preparation: \", time.time()-start_read, ' s')\n",
    "\n",
    "            # y zero the parameter gradients\n",
    "            start_inf_loss_back = time.time()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ds, fs = net(labels_v)#net(inputs_v)\n",
    "            loss2, loss = net.compute_loss(ds, labels_v)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_tar_loss += loss2.item()\n",
    "\n",
    "            # del outputs, loss\n",
    "            del ds, loss2, loss\n",
    "            end_inf_loss_back = time.time()-start_inf_loss_back\n",
    "\n",
    "            print(\"GT Encoder Training>>>\"+model_path.split('/')[-1]+\" - [epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f, time-per-iter: %3f s, time_read: %3f\" % (\n",
    "            epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val, time.time()-start_last, time.time()-start_last-end_inf_loss_back))\n",
    "            start_last = time.time()\n",
    "\n",
    "            if ite_num % model_save_fre == 0:  # validate every 2000 iterations\n",
    "                notgood_cnt += 1\n",
    "                # net.eval()\n",
    "                # tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid_gt_encoder(net, valid_dataloaders, valid_datasets, hypar, epoch)\n",
    "                tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid_gt_encoder(net, train_dataloaders_val, train_datasets_val, hypar, epoch)\n",
    "\n",
    "                net.train()  # resume train\n",
    "\n",
    "                tmp_out = 0\n",
    "                print(\"last_f1:\",last_f1)\n",
    "                print(\"tmp_f1:\",tmp_f1)\n",
    "                for fi in range(len(last_f1)):\n",
    "                    if(tmp_f1[fi]>last_f1[fi]):\n",
    "                        tmp_out = 1\n",
    "                print(\"tmp_out:\",tmp_out)\n",
    "                if(tmp_out):\n",
    "                    notgood_cnt = 0\n",
    "                    last_f1 = tmp_f1\n",
    "                    tmp_f1_str = [str(round(f1x,4)) for f1x in tmp_f1]\n",
    "                    tmp_mae_str = [str(round(mx,4)) for mx in tmp_mae]\n",
    "                    maxf1 = '_'.join(tmp_f1_str)\n",
    "                    meanM = '_'.join(tmp_mae_str)\n",
    "                    # .cpu().detach().numpy()\n",
    "                    model_name = \"/GTENCODER-gpu_itr_\"+str(ite_num)+\\\n",
    "                                \"_traLoss_\"+str(np.round(running_loss / ite_num4val,4))+\\\n",
    "                                \"_traTarLoss_\"+str(np.round(running_tar_loss / ite_num4val,4))+\\\n",
    "                                \"_valLoss_\"+str(np.round(val_loss /(i_val+1),4))+\\\n",
    "                                \"_valTarLoss_\"+str(np.round(tar_loss /(i_val+1),4)) + \\\n",
    "                                \"_maxF1_\" + maxf1 + \\\n",
    "                                \"_mae_\" + meanM + \\\n",
    "                                \"_time_\" + str(np.round(np.mean(np.array(tmp_time))/batch_size_valid,6))+\".pth\"\n",
    "                    torch.save(net.state_dict(), model_path + model_name)\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_tar_loss = 0.0\n",
    "                ite_num4val = 0\n",
    "\n",
    "                if(tmp_f1[0]>0.99):\n",
    "                    print(\"GT encoder is well-trained and obtained...\")\n",
    "                    return net\n",
    "\n",
    "                if(notgood_cnt >= hypar[\"early_stop\"]):\n",
    "                    print(\"No improvements in the last \"+str(notgood_cnt)+\" validation periods, so training stopped !\")\n",
    "                    exit()\n",
    "\n",
    "    print(\"Training Reaches The Maximum Epoch Number\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ea4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_gt_encoder(net, valid_dataloaders, valid_datasets, hypar, epoch=0):\n",
    "    net.eval()\n",
    "    print(\"Validating...\")\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "\n",
    "    val_loss = 0.0\n",
    "    tar_loss = 0.0\n",
    "\n",
    "\n",
    "    tmp_f1 = []\n",
    "    tmp_mae = []\n",
    "    tmp_time = []\n",
    "\n",
    "    start_valid = time.time()\n",
    "    for k in range(len(valid_dataloaders)):\n",
    "\n",
    "        valid_dataloader = valid_dataloaders[k]\n",
    "        valid_dataset = valid_datasets[k]\n",
    "\n",
    "        val_num = valid_dataset.__len__()\n",
    "        mybins = np.arange(0,256)\n",
    "        PRE = np.zeros((val_num,len(mybins)-1))\n",
    "        REC = np.zeros((val_num,len(mybins)-1))\n",
    "        F1 = np.zeros((val_num,len(mybins)-1))\n",
    "        MAE = np.zeros((val_num))\n",
    "\n",
    "        val_cnt = 0.0\n",
    "        i_val = None\n",
    "\n",
    "        for i_val, data_val in enumerate(valid_dataloader):\n",
    "\n",
    "            # imidx_val, inputs_val, labels_val, shapes_val = data_val['imidx'], data_val['image'], data_val['label'], data_val['shape']\n",
    "            imidx_val, labels_val, shapes_val = data_val['imidx'], data_val['label'], data_val['shape']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                labels_val = labels_val.type(torch.FloatTensor)\n",
    "            else:\n",
    "                labels_val = labels_val.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                labels_val_v = Variable(labels_val.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                labels_val_v = Variable(labels_val,requires_grad=False)\n",
    "\n",
    "            t_start = time.time()\n",
    "            ds_val = net(labels_val_v)[0]\n",
    "            t_end = time.time()-t_start\n",
    "            tmp_time.append(t_end)\n",
    "\n",
    "            # loss2_val, loss_val = muti_loss_fusion(ds_val, labels_val_v)\n",
    "            loss2_val, loss_val = net.compute_loss(ds_val, labels_val_v)\n",
    "\n",
    "            # compute F measure\n",
    "            for t in range(hypar[\"batch_size_valid\"]):\n",
    "                val_cnt = val_cnt + 1.0\n",
    "                print(\"num of val: \", val_cnt)\n",
    "                i_test = imidx_val[t].data.numpy()\n",
    "\n",
    "                pred_val = ds_val[0][t,:,:,:] # B x 1 x H x W\n",
    "\n",
    "                ## recover the prediction spatial size to the orignal image size\n",
    "                pred_val = torch.squeeze(F.upsample(torch.unsqueeze(pred_val,0),(shapes_val[t][0],shapes_val[t][1]),mode='bilinear'))\n",
    "\n",
    "                ma = torch.max(pred_val)\n",
    "                mi = torch.min(pred_val)\n",
    "                pred_val = (pred_val-mi)/(ma-mi) # max = 1\n",
    "                # pred_val = normPRED(pred_val)\n",
    "\n",
    "                gt = np.squeeze(io.imread(valid_dataset.dataset[\"ori_gt_path\"][i_test])) # max = 255\n",
    "                with torch.no_grad():\n",
    "                    gt = torch.tensor(gt).to(device)\n",
    "\n",
    "                pre,rec,f1,mae = f1_mae_torch(pred_val*255, gt, valid_dataset, i_test, mybins, hypar)\n",
    "\n",
    "                PRE[i_test,:]=pre\n",
    "                REC[i_test,:] = rec\n",
    "                F1[i_test,:] = f1\n",
    "                MAE[i_test] = mae\n",
    "\n",
    "            del ds_val, gt\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # if(loss_val.data[0]>1):\n",
    "            val_loss += loss_val.item()#data[0]\n",
    "            tar_loss += loss2_val.item()#data[0]\n",
    "\n",
    "            print(\"[validating: %5d/%5d] val_ls:%f, tar_ls: %f, f1: %f, mae: %f, time: %f\"% (i_val, val_num, val_loss / (i_val + 1), tar_loss / (i_val + 1), np.amax(F1[i_test,:]), MAE[i_test],t_end))\n",
    "\n",
    "            del loss2_val, loss_val\n",
    "\n",
    "        print('============================')\n",
    "        PRE_m = np.mean(PRE,0)\n",
    "        REC_m = np.mean(REC,0)\n",
    "        f1_m = (1+0.3)*PRE_m*REC_m/(0.3*PRE_m+REC_m+1e-8)\n",
    "        # print('--------------:', np.mean(f1_m))\n",
    "        tmp_f1.append(np.amax(f1_m))\n",
    "        tmp_mae.append(np.mean(MAE))\n",
    "        print(\"The max F1 Score: %f\"%(np.max(f1_m)))\n",
    "        print(\"MAE: \", np.mean(MAE))\n",
    "\n",
    "    # print('[epoch: %3d/%3d, ite: %5d] tra_ls: %3f, val_ls: %3f, tar_ls: %3f, maxf1: %3f, val_time: %6f'% (epoch + 1, epoch_num, ite_num, running_loss / ite_num4val, val_loss/val_cnt, tar_loss/val_cnt, tmp_f1[-1], time.time()-start_valid))\n",
    "\n",
    "    return tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, train_dataloaders, train_datasets, valid_dataloaders, valid_datasets, hypar,train_dataloaders_val, train_datasets_val): #model_path, model_save_fre, max_ite=1000000):\n",
    "\n",
    "    if hypar[\"interm_sup\"]:\n",
    "        print(\"Get the gt encoder ...\")\n",
    "        featurenet = get_gt_encoder(train_dataloaders, train_datasets, valid_dataloaders, valid_datasets, hypar,train_dataloaders_val, train_datasets_val)\n",
    "        ## freeze the weights of gt encoder\n",
    "        for param in featurenet.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "\n",
    "    model_path = hypar[\"model_path\"]\n",
    "    model_save_fre = hypar[\"model_save_fre\"]\n",
    "    max_ite = hypar[\"max_ite\"]\n",
    "    batch_size_train = hypar[\"batch_size_train\"]\n",
    "    batch_size_valid = hypar[\"batch_size_valid\"]\n",
    "\n",
    "    if(not os.path.exists(model_path)):\n",
    "        os.mkdir(model_path)\n",
    "\n",
    "    ite_num = hypar[\"start_ite\"] # count the toal iteration number\n",
    "    ite_num4val = 0 #\n",
    "    running_loss = 0.0 # count the toal loss\n",
    "    running_tar_loss = 0.0 # count the target output loss\n",
    "    last_f1 = [0 for x in range(len(valid_dataloaders))]\n",
    "\n",
    "    train_num = train_datasets[0].__len__()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    start_last = time.time()\n",
    "    gos_dataloader = train_dataloaders[0]\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "    notgood_cnt = 0\n",
    "    for epoch in range(epoch_num): ## set the epoch num as 100000\n",
    "\n",
    "        for i, data in enumerate(gos_dataloader):\n",
    "\n",
    "            if(ite_num >= max_ite):\n",
    "                print(\"Training Reached the Maximal Iteration Number \", max_ite)\n",
    "                exit()\n",
    "\n",
    "            # start_read = time.time()\n",
    "            ite_num = ite_num + 1\n",
    "            ite_num4val = ite_num4val + 1\n",
    "\n",
    "            # get the inputs\n",
    "            inputs, labels = data['image'], data['label']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                inputs = inputs.type(torch.FloatTensor)\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "            else:\n",
    "                inputs = inputs.type(torch.HalfTensor)\n",
    "                labels = labels.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "            # print(\"time lapse for data preparation: \", time.time()-start_read, ' s')\n",
    "\n",
    "            # y zero the parameter gradients\n",
    "            start_inf_loss_back = time.time()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if hypar[\"interm_sup\"]:\n",
    "                # forward + backward + optimize\n",
    "                ds,dfs = net(inputs_v)\n",
    "                _,fs = featurenet(labels_v) ## extract the gt encodings\n",
    "                loss2, loss = net.compute_loss_kl(ds, labels_v, dfs, fs, mode='MSE')\n",
    "            else:\n",
    "                # forward + backward + optimize\n",
    "                ds,_ = net(inputs_v)\n",
    "                loss2, loss = net.compute_loss(ds, labels_v)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_tar_loss += loss2.item()\n",
    "\n",
    "            # del outputs, loss\n",
    "            del ds, loss2, loss\n",
    "            end_inf_loss_back = time.time()-start_inf_loss_back\n",
    "\n",
    "            print(\">>>\"+model_path.split('/')[-1]+\" - [epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f, time-per-iter: %3f s, time_read: %3f\" % (\n",
    "            epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val, time.time()-start_last, time.time()-start_last-end_inf_loss_back))\n",
    "            start_last = time.time()\n",
    "\n",
    "            if ite_num % model_save_fre == 0:  # validate every 2000 iterations\n",
    "                notgood_cnt += 1\n",
    "                net.eval()\n",
    "                tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time = valid(net, valid_dataloaders, valid_datasets, hypar, epoch)\n",
    "                net.train()  # resume train\n",
    "\n",
    "                tmp_out = 0\n",
    "                print(\"last_f1:\",last_f1)\n",
    "                print(\"tmp_f1:\",tmp_f1)\n",
    "                for fi in range(len(last_f1)):\n",
    "                    if(tmp_f1[fi]>last_f1[fi]):\n",
    "                        tmp_out = 1\n",
    "                print(\"tmp_out:\",tmp_out)\n",
    "                if(tmp_out):\n",
    "                    notgood_cnt = 0\n",
    "                    last_f1 = tmp_f1\n",
    "                    tmp_f1_str = [str(round(f1x,4)) for f1x in tmp_f1]\n",
    "                    tmp_mae_str = [str(round(mx,4)) for mx in tmp_mae]\n",
    "                    maxf1 = '_'.join(tmp_f1_str)\n",
    "                    meanM = '_'.join(tmp_mae_str)\n",
    "                    # .cpu().detach().numpy()\n",
    "                    model_name = \"/gpu_itr_\"+str(ite_num)+\\\n",
    "                                \"_traLoss_\"+str(np.round(running_loss / ite_num4val,4))+\\\n",
    "                                \"_traTarLoss_\"+str(np.round(running_tar_loss / ite_num4val,4))+\\\n",
    "                                \"_valLoss_\"+str(np.round(val_loss /(i_val+1),4))+\\\n",
    "                                \"_valTarLoss_\"+str(np.round(tar_loss /(i_val+1),4)) + \\\n",
    "                                \"_maxF1_\" + maxf1 + \\\n",
    "                                \"_mae_\" + meanM + \\\n",
    "                                \"_time_\" + str(np.round(np.mean(np.array(tmp_time))/batch_size_valid,6))+\".pth\"\n",
    "                    torch.save(net.state_dict(), model_path + model_name)\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_tar_loss = 0.0\n",
    "                ite_num4val = 0\n",
    "\n",
    "                if(notgood_cnt >= hypar[\"early_stop\"]):\n",
    "                    print(\"No improvements in the last \"+str(notgood_cnt)+\" validation periods, so training stopped !\")\n",
    "                    exit()\n",
    "\n",
    "    print(\"Training Reaches The Maximum Epoch Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17505a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(net, valid_dataloaders, valid_datasets, hypar, epoch=0):\n",
    "    net.eval()\n",
    "    print(\"Validating...\")\n",
    "    epoch_num = hypar[\"max_epoch_num\"]\n",
    "\n",
    "    val_loss = 0.0\n",
    "    tar_loss = 0.0\n",
    "    val_cnt = 0.0\n",
    "\n",
    "    tmp_f1 = []\n",
    "    tmp_mae = []\n",
    "    tmp_time = []\n",
    "\n",
    "    start_valid = time.time()\n",
    "    print('---------------')\n",
    "    print(len(valid_dataloaders))\n",
    "    print('------------')\n",
    "\n",
    "    for k in range(len(valid_dataloaders)):\n",
    "\n",
    "        valid_dataloader = valid_dataloaders[k]\n",
    "        valid_dataset = valid_datasets[k]\n",
    "\n",
    "        val_num = valid_dataset.__len__()\n",
    "        mybins = np.arange(0,256)\n",
    "        PRE = np.zeros((val_num,len(mybins)-1))\n",
    "        REC = np.zeros((val_num,len(mybins)-1))\n",
    "        F1 = np.zeros((val_num,len(mybins)-1))\n",
    "        MAE = np.zeros((val_num))\n",
    "        \n",
    "        print('---------------')\n",
    "        print(enumerate(valid_dataloader))\n",
    "        print('------------')\n",
    "        \n",
    "        for i_val, data_val in enumerate(valid_dataloader):\n",
    "            val_cnt = val_cnt + 1.0\n",
    "            imidx_val, inputs_val, labels_val, shapes_val = data_val['imidx'], data_val['image'], data_val['label'], data_val['shape']\n",
    "\n",
    "            if(hypar[\"model_digit\"]==\"full\"):\n",
    "                inputs_val = inputs_val.type(torch.FloatTensor)\n",
    "                labels_val = labels_val.type(torch.FloatTensor)\n",
    "            else:\n",
    "                inputs_val = inputs_val.type(torch.HalfTensor)\n",
    "                labels_val = labels_val.type(torch.HalfTensor)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_val_v, labels_val_v = Variable(inputs_val.cuda(), requires_grad=False), Variable(labels_val.cuda(), requires_grad=False)\n",
    "            else:\n",
    "                inputs_val_v, labels_val_v = Variable(inputs_val, requires_grad=False), Variable(labels_val,requires_grad=False)\n",
    "\n",
    "            t_start = time.time()\n",
    "            ds_val = net(inputs_val_v)[0]\n",
    "            t_end = time.time()-t_start\n",
    "            tmp_time.append(t_end)\n",
    "\n",
    "            # loss2_val, loss_val = muti_loss_fusion(ds_val, labels_val_v)\n",
    "            loss2_val, loss_val = net.compute_loss(ds_val, labels_val_v)\n",
    "\n",
    "            # compute F measure\n",
    "            for t in range(hypar[\"batch_size_valid\"]):\n",
    "                i_test = imidx_val[t].data.numpy()\n",
    "\n",
    "                pred_val = ds_val[0][t,:,:,:] # B x 1 x H x W\n",
    "\n",
    "                ## recover the prediction spatial size to the orignal image size\n",
    "                pred_val = torch.squeeze(F.upsample(torch.unsqueeze(pred_val,0),(shapes_val[t][0],shapes_val[t][1]),mode='bilinear'))\n",
    "\n",
    "                # pred_val = normPRED(pred_val)\n",
    "                ma = torch.max(pred_val)\n",
    "                mi = torch.min(pred_val)\n",
    "                pred_val = (pred_val-mi)/(ma-mi) # max = 1\n",
    "\n",
    "                if len(valid_dataset.dataset[\"ori_gt_path\"]) != 0:\n",
    "                    gt = np.squeeze(io.imread(valid_dataset.dataset[\"ori_gt_path\"][i_test])) # max = 255\n",
    "                else:\n",
    "                    gt = np.zeros((shapes_val[t][0],shapes_val[t][1]))\n",
    "                with torch.no_grad():\n",
    "                    gt = torch.tensor(gt).to(device)\n",
    "\n",
    "                pre,rec,f1,mae = f1_mae_torch(pred_val*255, gt, valid_dataset, i_test, mybins, hypar)\n",
    "\n",
    "\n",
    "                PRE[i_test,:]=pre\n",
    "                REC[i_test,:] = rec\n",
    "                F1[i_test,:] = f1\n",
    "                MAE[i_test] = mae\n",
    "\n",
    "                del ds_val, gt\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # if(loss_val.data[0]>1):\n",
    "            val_loss += loss_val.item()#data[0]\n",
    "            tar_loss += loss2_val.item()#data[0]\n",
    "\n",
    "            print(\"[validating: %5d/%5d] val_ls:%f, tar_ls: %f, f1: %f, mae: %f, time: %f\"% (i_val, val_num, val_loss / (i_val + 1), tar_loss / (i_val + 1), np.amax(F1[i_test,:]), MAE[i_test],t_end))\n",
    "\n",
    "            del loss2_val, loss_val\n",
    "\n",
    "        print('============================')\n",
    "        PRE_m = np.mean(PRE,0)\n",
    "        REC_m = np.mean(REC,0)\n",
    "        f1_m = (1+0.3)*PRE_m*REC_m/(0.3*PRE_m+REC_m+1e-8)\n",
    "\n",
    "        tmp_f1.append(np.amax(f1_m))\n",
    "        tmp_mae.append(np.mean(MAE))\n",
    "\n",
    "    return tmp_f1, tmp_mae, val_loss, tar_loss, i_val, tmp_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d80d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_datasets,\n",
    "         valid_datasets,\n",
    "         hypar): # model: \"train\", \"test\"\n",
    "\n",
    "    ### --- Step 1: Build datasets and dataloaders ---\n",
    "    dataloaders_train = []\n",
    "    dataloaders_valid = []\n",
    "\n",
    "    if(hypar[\"mode\"]==\"train\"):\n",
    "        print(\"--- create training dataloader ---\")\n",
    "        ## collect training dataset\n",
    "        train_nm_im_gt_list = get_im_gt_name_dict(train_datasets, flag=\"train\")\n",
    "        ## build dataloader for training datasets\n",
    "        train_dataloaders, train_datasets = create_dataloaders(train_nm_im_gt_list,\n",
    "                                                             cache_size = hypar[\"cache_size\"],\n",
    "                                                             cache_boost = hypar[\"cache_boost_train\"],\n",
    "                                                             my_transforms = [\n",
    "                                                                             GOSRandomHFlip(), ## this line can be uncommented for horizontal flip augmetation\n",
    "                                                                             # GOSResize(hypar[\"input_size\"]),\n",
    "                                                                             # GOSRandomCrop(hypar[\"crop_size\"]), ## this line can be uncommented for randomcrop augmentation\n",
    "                                                                              GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                              ],\n",
    "                                                             batch_size = hypar[\"batch_size_train\"],\n",
    "                                                             shuffle = True)\n",
    "        train_dataloaders_val, train_datasets_val = create_dataloaders(train_nm_im_gt_list,\n",
    "                                                             cache_size = hypar[\"cache_size\"],\n",
    "                                                             cache_boost = hypar[\"cache_boost_train\"],\n",
    "                                                             my_transforms = [\n",
    "                                                                              GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                              ],\n",
    "                                                             batch_size = hypar[\"batch_size_valid\"],\n",
    "                                                             shuffle = False)\n",
    "        print(len(train_dataloaders), \" train dataloaders created\")\n",
    "\n",
    "    print(\"--- create valid dataloader ---\")\n",
    "    ## build dataloader for validation or testing\n",
    "    valid_nm_im_gt_list = get_im_gt_name_dict(valid_datasets, flag=\"valid\")\n",
    "    ## build dataloader for training datasets\n",
    "    valid_dataloaders, valid_datasets = create_dataloaders(valid_nm_im_gt_list,\n",
    "                                                          cache_size = hypar[\"cache_size\"],\n",
    "                                                          cache_boost = hypar[\"cache_boost_valid\"],\n",
    "                                                          my_transforms = [\n",
    "                                                                           GOSNormalize([0.5,0.5,0.5],[1.0,1.0,1.0]),\n",
    "                                                                           # GOSResize(hypar[\"input_size\"])\n",
    "                                                                           ],\n",
    "                                                          batch_size=hypar[\"batch_size_valid\"],\n",
    "                                                          shuffle=False)\n",
    "    print(len(valid_dataloaders), \" valid dataloaders created\")\n",
    "    # print(valid_datasets[0][\"data_name\"])\n",
    "\n",
    "    ### --- Step 2: Build Model and Optimizer ---\n",
    "    print(\"--- build model ---\")\n",
    "    net = hypar[\"model\"]#GOSNETINC(3,1)\n",
    "\n",
    "    # convert to half precision\n",
    "    if(hypar[\"model_digit\"]==\"half\"):\n",
    "        net.half()\n",
    "        for layer in net.modules():\n",
    "              if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    if(hypar[\"restore_model\"]!=\"\"):\n",
    "        print(\"restore model from:\")\n",
    "        print(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"])\n",
    "        if torch.cuda.is_available():\n",
    "            net.load_state_dict(torch.load(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"]))\n",
    "        else:\n",
    "            net.load_state_dict(torch.load(hypar[\"model_path\"]+\"/\"+hypar[\"restore_model\"],map_location=\"cpu\"))\n",
    "        print(\"loading pretrained model done\")\n",
    "\n",
    "    print(\"--- define optimizer ---\")\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    ### --- Step 3: Train or Valid Model ---\n",
    "    if(hypar[\"mode\"]==\"train\"):\n",
    "        train(net,\n",
    "              optimizer,\n",
    "              train_dataloaders,\n",
    "              train_datasets,\n",
    "              valid_dataloaders,\n",
    "              valid_datasets,\n",
    "              hypar,\n",
    "              train_dataloaders_val, train_datasets_val)\n",
    "    else:\n",
    "        valid(net,\n",
    "              valid_dataloaders,\n",
    "              valid_datasets,\n",
    "              hypar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc48ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ISNetDIS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m## --- 2.5. define model  ---\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilding model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m hypar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ISNetDIS() \u001b[38;5;66;03m#U2NETFASTFEATURESUP()\u001b[39;00m\n\u001b[1;32m     72\u001b[0m hypar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m## stop the training when no improvement in the past 20 validation periods, smaller numbers can be used here e.g., 5 or 10.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m hypar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_save_fre\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;66;03m## valid and save model weights every 2000 iterations\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ISNetDIS' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ### --------------- STEP 1: Configuring the Train, Valid and Test datasets ---------------\n",
    "    ## configure the train, valid and inference datasets\n",
    "    train_datasets, valid_datasets = [], []\n",
    "    dataset_1, dataset_1 = {}, {}\n",
    "\n",
    "    dataset_tr = {\"name\": \"dataset\",\n",
    "                 \"im_dir\": \"./dataset/train\",\n",
    "                 \"gt_dir\": \"./dataset/train_mask\",\n",
    "                 \"im_ext\": \".jpg\",\n",
    "                 \"gt_ext\": \".png\",\n",
    "                 \"cache_dir\":\"./dataset/train\"}\n",
    "\n",
    "    dataset_vd = {\"name\": \"dataset_val\",\n",
    "                 \"im_dir\": \"./dataset_val/train\",\n",
    "                 \"gt_dir\": \"./dataset_val/train_mask\",\n",
    "                 \"im_ext\": \".jpg\",\n",
    "                 \"gt_ext\": \".png\",\n",
    "                 \"cache_dir\":\"./dataset_val/train\"}\n",
    "\n",
    "\n",
    "    train_datasets = [dataset_tr] ## users can create mutiple dictionary for setting a list of datasets as training set\n",
    "    # valid_datasets = [dataset_vd] ## users can create mutiple dictionary for setting a list of datasets as vaidation sets or inference sets\n",
    "    valid_datasets = [dataset_vd] # dataset_vd, dataset_te1, dataset_te2, dataset_te3, dataset_te4] # and hypar[\"mode\"] = \"valid\" for inference,\n",
    "\n",
    "    ### --------------- STEP 2: Configuring the hyperparamters for Training, validation and inferencing ---------------\n",
    "    hypar = {}\n",
    "\n",
    "    ## -- 2.1. configure the model saving or restoring path --\n",
    "    hypar[\"mode\"] = \"train\"\n",
    "    ## \"train\": for training,\n",
    "    ## \"valid\": for validation and inferening,\n",
    "    ## in \"valid\" mode, it will calculate the accuracy as well as save the prediciton results into the \"hypar[\"valid_out_dir\"]\", which shouldn't be \"\"\n",
    "    ## otherwise only accuracy will be calculated and no predictions will be saved\n",
    "    hypar[\"interm_sup\"] = False ## in-dicate if activate intermediate feature supervision\n",
    "\n",
    "    if hypar[\"mode\"] == \"train\":\n",
    "        hypar[\"valid_out_dir\"] = \"\" ## for \"train\" model leave it as \"\", for \"valid\"(\"inference\") mode: set it according to your local directory\n",
    "        hypar[\"model_path\"] =\"../saved_models\" ## model weights saving (or restoring) path\n",
    "        hypar[\"restore_model\"] = \"isnet.pth\" ## name of the segmentation model weights .pth for resume training process from last stop or for the inferencing\n",
    "        hypar[\"start_ite\"] = 0 ## start iteration for the training, can be changed to match the restored training process\n",
    "        hypar[\"gt_encoder_model\"] = \"\"\n",
    "    else: ## configure the segmentation output path and the to-be-used model weights path\n",
    "        hypar[\"valid_out_dir\"] = \"../your-results/\"##\"../DIS5K-Results-test\" ## output inferenced segmentation maps into this fold\n",
    "        hypar[\"model_path\"] = \"../saved_models\" ## load trained weights from this path\n",
    "        hypar[\"restore_model\"] = \"isnet.pth\"##\"isnet.pth\" ## name of the to-be-loaded weights\n",
    "\n",
    "    # if hypar[\"restore_model\"]!=\"\":\n",
    "    #     hypar[\"start_ite\"] = int(hypar[\"restore_model\"].split(\"_\")[2])\n",
    "\n",
    "    ## -- 2.2. choose floating point accuracy --\n",
    "    hypar[\"model_digit\"] = \"full\" ## indicates \"half\" or \"full\" accuracy of float number\n",
    "    hypar[\"seed\"] = 0\n",
    "\n",
    "    ## -- 2.3. cache data spatial size --\n",
    "    ## To handle large size input images, which take a lot of time for loading in training,\n",
    "    #  we introduce the cache mechanism for pre-convering and resizing the jpg and png images into .pt file\n",
    "    hypar[\"cache_size\"] = [1024, 1024] ## cached input spatial resolution, can be configured into different size\n",
    "    hypar[\"cache_boost_train\"] = False ## \"True\" or \"False\", indicates wheather to load all the training datasets into RAM, True will greatly speed the training process while requires more RAM\n",
    "    hypar[\"cache_boost_valid\"] = False ## \"True\" or \"False\", indicates wheather to load all the validation datasets into RAM, True will greatly speed the training process while requires more RAM\n",
    "\n",
    "    ## --- 2.4. data augmentation parameters ---\n",
    "    hypar[\"input_size\"] = [1024, 1024] ## mdoel input spatial size, usually use the same value hypar[\"cache_size\"], which means we don't further resize the images\n",
    "    hypar[\"crop_size\"] = [1024, 1024] ## random crop size from the input, it is usually set as smaller than hypar[\"cache_size\"], e.g., [920,920] for data augmentation\n",
    "    hypar[\"random_flip_h\"] = 1 ## horizontal flip, currently hard coded in the dataloader and it is not in use\n",
    "    hypar[\"random_flip_v\"] = 0 ## vertical flip , currently not in use\n",
    "\n",
    "    ## --- 2.5. define model  ---\n",
    "    print(\"building model...\")\n",
    "    hypar[\"model\"] = ISNetDIS() #U2NETFASTFEATURESUP()\n",
    "    hypar[\"early_stop\"] = 20 ## stop the training when no improvement in the past 20 validation periods, smaller numbers can be used here e.g., 5 or 10.\n",
    "    hypar[\"model_save_fre\"] = 10 ## valid and save model weights every 2000 iterations\n",
    "\n",
    "    hypar[\"batch_size_train\"] = 1 ## batch size for training\n",
    "    hypar[\"batch_size_valid\"] = 1 ## batch size for validation and inferencing\n",
    "    print(\"batch size: \", hypar[\"batch_size_train\"])\n",
    "\n",
    "    hypar[\"max_ite\"] = 10000000 ## if early stop couldn't stop the training process, stop it by the max_ite_num\n",
    "    hypar[\"max_epoch_num\"] = 1000000 ## if early stop and max_ite couldn't stop the training process, stop it by the max_epoch_num\n",
    "\n",
    "    main(train_datasets,\n",
    "         valid_datasets,\n",
    "         hypar=hypar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "066f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import transform\n",
    "\n",
    "def __blur_edges__(mask):\n",
    "    \"\"\"\n",
    "    Blurs the edges of the image\n",
    "    :param mask: numpy mask\n",
    "    :return: blurred numpy mask\n",
    "    \"\"\"\n",
    "    aa = cv2.GaussianBlur(mask, (3, 3), sigmaX=0, sigmaY=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    # stretch so that 255 -> 255 and 127.5 -> 0\n",
    "    aa = skimage.exposure.rescale_intensity(aa, in_range=(230, 255), out_range=(0, 255))\n",
    "    return aa.astype(np.uint8)\n",
    "\n",
    "for image_name in os.listdir(os.path.join(\"dataset\",\"train_mask\")):\n",
    "    mask = Image.open(os.path.join(\"dataset\",\"train_mask\",image_name))\n",
    "    mask = np.array(mask).copy()\n",
    "                      \n",
    "    \n",
    "    ret, thresh = cv2.threshold(mask, 220, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    white_img = np.full(mask.shape,(255), dtype=np.uint8)\n",
    "#     black_img = np.full(mask.shape,(0), dtype=np.uint8)\n",
    "    if contours!=0:\n",
    "        cnt_max = max(contours, key = cv2.contourArea)\n",
    "        max_area = cv2.contourArea(cnt_max)\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt)<max_area and cv2.contourArea(cnt)>400:\n",
    "                cv2.drawContours(white_img, [cnt], 0,color=(0),thickness=-1)\n",
    "                white_img = __blur_edges__(white_img)\n",
    "                mask = np.where(mask,white_img,white_img)\n",
    "    plt.imshow(mask)\n",
    "                \n",
    "#     Image.fromarray(mask).save(os.path.join(\"u2net_dataset_master\",\"mask\",image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d4cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
